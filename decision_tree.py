"""
Modelo de Ãrbol de DecisiÃ³n para AnÃ¡lisis de Eficiencia - Challenge Ingelean
=========================================================================

Este mÃ³dulo implementa un modelo de Ã¡rbol de decisiÃ³n para predecir la eficiencia
porcentual usando el dataset procesado de manufactura.

Autor: FabiÃ¡n Rodriguez
Fecha: 2024
"""

import os
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv

class DecisionTreeModel:
    """
    Modelo de Ãrbol de DecisiÃ³n para predicciÃ³n de eficiencia porcentual.
    
    Esta clase implementa un modelo de Ã¡rbol de decisiÃ³n completo con preprocesamiento
    automÃ¡tico, entrenamiento, evaluaciÃ³n y visualizaciÃ³n de resultados.
    
    Attributes:
        df (pd.DataFrame): Dataset con los datos a procesar
        target_column (str): Nombre de la columna objetivo
        model (DecisionTreeRegressor): Modelo de sklearn entrenado
        results (dict): Diccionario con mÃ©tricas y resultados del modelo
        preprocessors (dict): Diccionario con objetos de preprocesamiento
    """
    
    def __init__(self, data_path=None, df=None, target_column='eficiencia_porcentual'):
        """
        Inicializa el modelo de Ã¡rbol de decisiÃ³n.
        
        Args:
            data_path (str, optional): Ruta al archivo de datos (Excel o CSV)
            df (pd.DataFrame, optional): DataFrame directamente cargado
            target_column (str, optional): Nombre de la columna objetivo.
                                         Por defecto 'eficiencia_porcentual'
        
        Raises:
            ValueError: Si no se proporciona ni data_path ni df
            
        Example:
            >>> # Usando DataFrame directamente
            >>> model = DecisionTreeModel(df=mi_dataframe)
            >>> 
            >>> # Usando archivo
            >>> model = DecisionTreeModel(data_path="datos.csv")
        """
        if df is not None:
            self.df = df.copy()
        elif data_path:
            self.load_data(data_path)
        else:
            raise ValueError("Debe proporcionar data_path o df")
            
        self.target_column = target_column
        self.model = None
        self.results = {}
        self.preprocessors = {}
        
    def load_data(self, data_path):
        """
        Carga los datos desde un archivo Excel o CSV.
        
        Args:
            data_path (str): Ruta al archivo de datos
            
        Raises:
            Exception: Si hay problemas al cargar el archivo
            
        Note:
            Detecta automÃ¡ticamente el formato del archivo basado en la extensiÃ³n.
        """
        try:
            if data_path.endswith('.xlsx'):
                self.df = pd.read_excel(data_path)
            else:
                self.df = pd.read_csv(data_path)
            print(f"Datos cargados exitosamente. Forma: {self.df.shape}")
        except Exception as e:
            print(f"Error al cargar los datos: {e}")
            raise

    def preprocess_data(self):
        """
        Preprocesa los datos para el entrenamiento del modelo de Ã¡rbol de decisiÃ³n.
        
        El preprocesamiento incluye:
        1. Limpieza de valores extremos y faltantes en la variable objetivo
        2. IdentificaciÃ³n de columnas categÃ³ricas y numÃ©ricas
        3. CodificaciÃ³n de variables categÃ³ricas usando LabelEncoder
        4. ImputaciÃ³n de valores faltantes en variables numÃ©ricas (media)
        5. PreparaciÃ³n del dataset final para entrenamiento
        
        Note:
            - Los valores extremos (>1e16) se eliminan para evitar problemas numÃ©ricos
            - Las columnas categÃ³ricas se codifican numÃ©ricamente
            - Los valores faltantes se imputan con la media de cada columna
            - Se actualiza self.df con los datos preprocesados
            
        Raises:
            KeyError: Si las columnas especificadas no existen en el dataset
        """
        # Limpieza bÃ¡sica
        self.df = self.df[self.df[self.target_column].notna()]
        self.df = self.df[self.df[self.target_column] < 1e16]  # Eliminar valores extremos
        
        # Columnas categÃ³ricas y numÃ©ricas
        self.categorical_cols = ['turno', 'operador_id', 'maquina_id', 'producto_id', 'fallo_detectado', 'tipo_fallo']
        self.numeric_cols = ['temperatura', 'vibracion', 'humedad', 'tiempo_ciclo', 
                           'cantidad_producida', 'unidades_defectuosas', 
                           'consumo_energia', 'paradas_programadas', 'paradas_imprevistas', 'fallos_binarios']
        
        # Asegurar que las columnas existan
        self.categorical_cols = [col for col in self.categorical_cols if col in self.df.columns]
        self.numeric_cols = [col for col in self.numeric_cols if col in self.df.columns]
        
        # 1. Codificar variables categÃ³ricas
        self.label_encoders = {}
        for col in self.categorical_cols:
            le = LabelEncoder()
            self.df[col] = le.fit_transform(self.df[col].astype(str))
            self.label_encoders[col] = le
        
        # 2. Imputar valores faltantes
        self.imputer = SimpleImputer(strategy='median')
        self.df[self.numeric_cols] = self.imputer.fit_transform(self.df[self.numeric_cols])
        
        # 3. NormalizaciÃ³n (guardamos parÃ¡metros para nuevos datos)
        self.numeric_means = self.df[self.numeric_cols].mean()
        self.numeric_stds = self.df[self.numeric_cols].std()
        self.df[self.numeric_cols] = (self.df[self.numeric_cols] - self.numeric_means) / self.numeric_stds
        
        # Guardar preprocesadores
        self.preprocessors = {
            'label_encoders': self.label_encoders,
            'imputer': self.imputer,
            'numeric_means': self.numeric_means,
            'numeric_stds': self.numeric_stds
        }

    def train_model(self, test_size=0.2, random_state=42, max_depth=5):
        """
        Entrena el modelo de Ã¡rbol de decisiÃ³n y evalÃºa su rendimiento.
        
        Args:
            test_size (float, optional): ProporciÃ³n del dataset para conjunto de prueba.
                                       Por defecto 0.2 (20%)
            random_state (int, optional): Semilla para reproducibilidad de resultados.
                                        Por defecto 42
            max_depth (int, optional): Profundidad mÃ¡xima del Ã¡rbol para evitar overfitting.
                                     Por defecto 5
        
        Returns:
            dict: Diccionario con mÃ©tricas de evaluaciÃ³n y resultados del modelo.
                 Incluye: 'metrics', 'feature_importance', 'predictions'
        
        Note:
            - Divide automÃ¡ticamente los datos en entrenamiento y prueba
            - Calcula mÃ©tricas: MSE, RMSE, MAE, RÂ²
            - Genera tabla de importancia de caracterÃ­sticas
            - Almacena resultados en self.results
            
        Example:
            >>> model = DecisionTreeModel(df=data)
            >>> model.preprocess_data()
            >>> results = model.train_model(test_size=0.3, max_depth=7)
            >>> print(f"RÂ² Score: {results['metrics']['r2']:.4f}")
        """
        # Preparar datos
        X = self.df[self.categorical_cols + self.numeric_cols]
        y = self.df[self.target_column]
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        # Crear y entrenar modelo
        self.model = DecisionTreeRegressor(
            max_depth=max_depth, 
            random_state=random_state
        )
        self.model.fit(X_train, y_train)
        
        # Evaluar
        y_pred = self.model.predict(X_test)
        
        # Calcular mÃ©tricas
        self.results = {
            'metrics': {
                'mse': mean_squared_error(y_test, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                'mae': mean_absolute_error(y_test, y_pred),
                'r2': r2_score(y_test, y_pred)
            },
            'feature_importance': self.get_feature_importance(),
            'test_predictions': pd.DataFrame({
                'Actual': y_test,
                'Predicted': y_pred
            })
        }
        
        return self.results

    def get_feature_importance(self):
        """Obtiene la importancia de las caracterÃ­sticas"""
        if self.model is None:
            raise ValueError("El modelo no ha sido entrenado aÃºn")
            
        importances = self.model.feature_importances_
        features = self.categorical_cols + self.numeric_cols
        feature_importance = pd.DataFrame({
            'Feature': features,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        
        return feature_importance

    def plot_tree(self, max_depth=3, figsize=(20, 10)):
        """Visualiza el Ã¡rbol de decisiÃ³n (parcial para evitar sobrecarga)"""
        if self.model is None:
            raise ValueError("El modelo no ha sido entrenado aÃºn")
            
        plt.figure(figsize=figsize)
        plot_tree(
            self.model, 
            feature_names=self.categorical_cols + self.numeric_cols,
            filled=True, 
            rounded=True,
            max_depth=max_depth,
            fontsize=10
        )
        plt.title("Ãrbol de DecisiÃ³n (primeros niveles)", pad=20)
        plt.tight_layout()
        plt.savefig('decision_tree.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_feature_importance(self, top_n=10):
        """Grafica la importancia de las caracterÃ­sticas"""
        importance_df = self.get_feature_importance()
        
        plt.figure(figsize=(10, 6))
        sns.barplot(
            x='Importance', 
            y='Feature', 
            data=importance_df.head(top_n),
            palette='viridis'
        )
        plt.title(f'Top {top_n} CaracterÃ­sticas MÃ¡s Importantes', pad=20)
        plt.xlabel('Importancia')
        plt.ylabel('CaracterÃ­stica')
        plt.tight_layout()
        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
        plt.show()

    def print_results(self):
        """Imprime los resultados del modelo"""
        if not self.results:
            print("No hay resultados para mostrar. Entrene el modelo primero.")
            return
        
        print("\n" + "="*50)
        print("RESULTADOS DEL ÃRBOL DE DECISIÃ“N")
        print("="*50)
        
        # MÃ©tricas
        print("\nMÃ©tricas de rendimiento:")
        print(f"- Error CuadrÃ¡tico Medio (MSE): {self.results['metrics']['mse']:.4f}")
        print(f"- RaÃ­z del Error CuadrÃ¡tico Medio (RMSE): {self.results['metrics']['rmse']:.4f}")
        print(f"- Error Absoluto Medio (MAE): {self.results['metrics']['mae']:.4f}")
        print(f"- Coeficiente RÂ²: {self.results['metrics']['r2']:.4f}")
        
        # Importancia de caracterÃ­sticas
        print("\nImportancia de las caracterÃ­sticas:")
        print(self.results['feature_importance'].to_string(index=False))
        
        print("\n" + "="*50)

def main():
    """
    FunciÃ³n principal que ejecuta el modelo de Ã¡rbol de decisiÃ³n usando el dataset procesado.
    
    Workflow:
        1. Carga del dataset procesado (Dataset_Talento_Procesado.csv)
        2. VerificaciÃ³n de datos
        3. Entrenamiento del modelo de Ã¡rbol de decisiÃ³n
        4. EvaluaciÃ³n y visualizaciÃ³n de resultados
        
    Files Used:
        - Dataset_Talento_Procesado.csv: Dataset con preprocesamiento aplicado
        
    Files Generated:
        - feature_importance.png: GrÃ¡fico de importancia de caracterÃ­sticas
        - decision_tree.png: VisualizaciÃ³n del Ã¡rbol de decisiÃ³n
    """
    print("ğŸŒ³ Iniciando Modelo de Ãrbol de DecisiÃ³n - Challenge Ingelean")
    print("=" * 65)
    
    # 1. CARGAR DATASET PROCESADO
    print("\nğŸ“ CARGANDO DATASET PROCESADO")
    print("-" * 40)
    
    dataset_path = "Dataset_Talento_Procesado.csv"
    
    if not os.path.exists(dataset_path):
        print(f"âŒ Error: No se encontrÃ³ el archivo {dataset_path}")
        print("ğŸ’¡ Ejecuta primero main.py para generar el dataset procesado")
        return
    
    try:
        df = pd.read_csv(dataset_path)
        print(f"âœ… Dataset cargado exitosamente: {dataset_path}")
        print(f"ğŸ“Š Forma del dataset: {df.shape}")
        print(f"ğŸ” Columnas disponibles: {list(df.columns)}")
        
        # Verificar que la columna objetivo existe
        target_column = 'eficiencia_porcentual'
        if target_column not in df.columns:
            print(f"âŒ Error: No se encontrÃ³ la columna objetivo '{target_column}'")
            return
            
        print(f"ğŸ¯ Variable objetivo: {target_column}")
        
    except Exception as e:
        print(f"âŒ Error al cargar el dataset: {str(e)}")
        return

    # 2. INFORMACIÃ“N DEL DATASET
    print(f"\nğŸ“‹ INFORMACIÃ“N DEL DATASET PROCESADO")
    print("-" * 40)
    print(f"âœ… Valores nulos eliminados mediante imputaciÃ³n")
    print(f"âœ… Variable 'fallos_binarios' agregada")
    print(f"ğŸ“Š Valores nulos restantes:")
    nulls = df.isnull().sum()
    print(nulls[nulls > 0] if nulls.sum() > 0 else "   Ninguno - Dataset completamente limpio")

    # 3. MODELADO CON ÃRBOL DE DECISIÃ“N
    print(f"\nğŸŒ³ ENTRENAMIENTO DEL MODELO")
    print("-" * 40)
    
    # Crear instancia del modelo
    dt_model = DecisionTreeModel(df=df, target_column=target_column)
    
    # Preprocesar datos
    print("ğŸ”§ Preprocesando datos para el modelo...")
    dt_model.preprocess_data()
    
    # Entrenar modelo
    print("âš™ï¸ Entrenando Ã¡rbol de decisiÃ³n...")
    results = dt_model.train_model(test_size=0.2, random_state=42, max_depth=5)
    
    # 4. RESULTADOS Y VISUALIZACIONES
    print(f"\nğŸ“Š RESULTADOS DEL MODELO")
    print("-" * 40)
    
    # Mostrar resultados
    dt_model.print_results()
    
    # Generar visualizaciones
    print(f"\nğŸ¨ GENERANDO VISUALIZACIONES")
    print("-" * 40)
    dt_model.plot_feature_importance(top_n=10)
    dt_model.plot_tree(max_depth=3)
    
    # 5. FINALIZACIÃ“N
    print(f"\nâœ… MODELADO COMPLETADO")
    print("=" * 65)
    print("ğŸ“ Archivos generados:")
    print("   â€¢ feature_importance.png")
    print("   â€¢ decision_tree.png")
    print(f"ğŸ¯ Modelo de Ã¡rbol de decisiÃ³n listo!")
    print(f"ğŸ“ˆ RÂ² Score: {results['metrics']['r2']:.4f}")
    print(f"ğŸ“‰ RMSE: {results['metrics']['rmse']:.4f}")

if __name__ == "__main__":
    main()