"""
Modelo de √Årbol de Decisi√≥n para An√°lisis de Eficiencia - Challenge Ingelean
=========================================================================

Este m√≥dulo implementa un modelo de √°rbol de decisi√≥n para predecir la eficiencia
porcentual usando el dataset procesado de manufactura.

Autor: Fabi√°n Rodriguez
Fecha: 2024
"""

import os
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv

def aplicar_arbol_decision(X, y, test_size=0.3, random_state=42, max_depth=None, criterion='gini'):
    """
    Aplica un modelo de √Årbol de Decisi√≥n y devuelve el modelo entrenado y las m√©tricas de evaluaci√≥n.
    
    Par√°metros:
    -----------
    X : array-like
        Variables predictoras (features)
    y : array-like
        Variable objetivo (target)
    test_size : float, opcional (default=0.3)
        Proporci√≥n del conjunto de prueba
    random_state : int, opcional (default=42)
        Semilla para reproducibilidad
    max_depth : int or None, opcional (default=None)
        Profundidad m√°xima del √°rbol. None significa que se expande hasta que todas las hojas sean puras.
    criterion : str, opcional (default='gini')
        Funci√≥n para medir la calidad de una divisi√≥n ('gini' o 'entropy')
    
    Retorna:
    --------
    model : DecisionTreeClassifier
        Modelo entrenado
    metrics : dict
        Diccionario con las m√©tricas de evaluaci√≥n
    """
    
    # Dividir los datos en entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
    
    # Crear y entrenar el modelo
    model = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=random_state)
    model.fit(X_train, y_train)
    
    # Predecir en el conjunto de prueba
    y_pred = model.predict(X_test)
    
    # Calcular m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    conf_matrix = confusion_matrix(y_test, y_pred)
    
    metrics = {
        'accuracy': accuracy,
        'classification_report': report,
        'confusion_matrix': conf_matrix
    }
    
    return model, metrics

def mostrar_metricas_clasificacion(metrics, feature_names=None, model=None):
    """
    Muestra las m√©tricas de clasificaci√≥n de manera legible y organizada.
    
    Par√°metros:
    -----------
    metrics : dict
        Diccionario con m√©tricas retornado por aplicar_arbol_decision
    feature_names : list, opcional
        Lista con nombres de las caracter√≠sticas para mostrar importancia
    model : DecisionTreeClassifier, opcional
        Modelo entrenado para mostrar importancia de caracter√≠sticas
    """
    print("\n" + "="*60)
    print("üéØ RESULTADOS DE CLASIFICACI√ìN DE FALLOS")
    print("="*60)
    
    # 1. PRECISI√ìN GENERAL
    print(f"\nüìà M√âTRICAS GENERALES")
    print("-" * 40)
    accuracy = metrics['accuracy']
    print(f"‚Ä¢ Precisi√≥n (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # Interpretaci√≥n de la precisi√≥n
    if accuracy >= 0.95:
        acc_interpretation = "Excelente precisi√≥n üéØ"
    elif accuracy >= 0.90:
        acc_interpretation = "Muy buena precisi√≥n üëç"
    elif accuracy >= 0.80:
        acc_interpretation = "Buena precisi√≥n ‚úÖ"
    elif accuracy >= 0.70:
        acc_interpretation = "Precisi√≥n aceptable ü§î"
    else:
        acc_interpretation = "Precisi√≥n baja - revisar modelo ‚ö†Ô∏è"
    
    print(f"‚Ä¢ Interpretaci√≥n: {acc_interpretation}")
    
    # 2. MATRIZ DE CONFUSI√ìN
    print(f"\nüîç MATRIZ DE CONFUSI√ìN")
    print("-" * 40)
    conf_matrix = metrics['confusion_matrix']
    
    # Etiquetas para la matriz
    print("Matriz de Confusi√≥n:")
    print("                 Predicci√≥n")
    print("                Sin Fallo  Con Fallo")
    print(f"Real Sin Fallo      {conf_matrix[0,0]:4d}      {conf_matrix[0,1]:4d}")
    print(f"Real Con Fallo      {conf_matrix[1,0]:4d}      {conf_matrix[1,1]:4d}")
    
    # Calcular m√©tricas adicionales
    tn, fp, fn, tp = conf_matrix.ravel()
    
    print(f"\nInterpretaci√≥n:")
    print(f"‚Ä¢ Verdaderos Negativos (TN): {tn} - Sin fallo predicho correctamente")
    print(f"‚Ä¢ Falsos Positivos (FP): {fp} - Fallos predichos incorrectamente")
    print(f"‚Ä¢ Falsos Negativos (FN): {fn} - Fallos no detectados")
    print(f"‚Ä¢ Verdaderos Positivos (TP): {tp} - Fallos detectados correctamente")
    
    # 3. M√âTRICAS POR CLASE
    print(f"\nüìä M√âTRICAS DETALLADAS POR CLASE")
    print("-" * 40)
    report = metrics['classification_report']
    
    # Clase 0 (Sin Fallo)
    class_0 = report['0']
    print(f"Sin Fallo (Clase 0):")
    print(f"  ‚Ä¢ Precisi√≥n:  {class_0['precision']:.4f}")
    print(f"  ‚Ä¢ Recall:     {class_0['recall']:.4f}")
    print(f"  ‚Ä¢ F1-Score:   {class_0['f1-score']:.4f}")
    print(f"  ‚Ä¢ Soporte:    {class_0['support']} muestras")
    
    # Clase 1 (Con Fallo)
    class_1 = report['1']
    print(f"\nCon Fallo (Clase 1):")
    print(f"  ‚Ä¢ Precisi√≥n:  {class_1['precision']:.4f}")
    print(f"  ‚Ä¢ Recall:     {class_1['recall']:.4f}")
    print(f"  ‚Ä¢ F1-Score:   {class_1['f1-score']:.4f}")
    print(f"  ‚Ä¢ Soporte:    {class_1['support']} muestras")
    
    # M√©tricas macro y weighted
    print(f"\nPromedios:")
    print(f"  ‚Ä¢ Macro avg F1:    {report['macro avg']['f1-score']:.4f}")
    print(f"  ‚Ä¢ Weighted avg F1: {report['weighted avg']['f1-score']:.4f}")
    
    # 4. IMPORTANCIA DE CARACTER√çSTICAS (si est√° disponible)
    if model is not None and feature_names is not None:
        print(f"\nüéØ IMPORTANCIA DE CARACTER√çSTICAS")
        print("-" * 40)
        
        importances = model.feature_importances_
        feature_importance = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        
        print("Top 10 caracter√≠sticas m√°s importantes para predecir fallos:")
        for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):
            feature_name = row['Feature']
            importance = row['Importance']
            
            # Crear barra visual
            bar_length = int(importance * 30)
            bar = "‚ñà" * min(bar_length, 15) + "‚ñë" * max(0, 8 - bar_length)
            
            print(f"{i:2d}. {feature_name:<22} {bar} {importance:.4f}")
    
    # 5. RECOMENDACIONES
    print(f"\nüí° RECOMENDACIONES")
    print("-" * 40)
    
    # An√°lisis de falsos positivos y negativos
    if fp > fn:
        print("‚Ä¢ Hay m√°s falsos positivos que negativos")
        print("‚Ä¢ El modelo tiende a 'sobrediagnosticar' fallos")
        print("‚Ä¢ Considerar ajustar el umbral de decisi√≥n")
    elif fn > fp:
        print("‚Ä¢ Hay m√°s falsos negativos que positivos")
        print("‚Ä¢ El modelo podr√≠a estar perdiendo fallos reales")
        print("‚Ä¢ Importante en contexto industrial - revisar par√°metros")
    else:
        print("‚Ä¢ Balance equilibrado entre falsos positivos y negativos")
    
    # An√°lisis del recall para fallos
    if class_1['recall'] < 0.8:
        print("‚Ä¢ Recall bajo para detectar fallos - cr√≠tico en manufactura")
        print("‚Ä¢ Considerar ajustar max_depth o usar criterion='entropy'")
    else:
        print("‚Ä¢ Buen recall para detecci√≥n de fallos")
    
    print("\n" + "="*60)

def clasificar_fallos_con_arbol(data_path="Dataset_Talento_Procesado.csv", test_size=0.3, max_depth=5, criterion='gini'):
    """
    Aplica clasificaci√≥n de fallos usando la funci√≥n aplicar_arbol_decision.
    
    Par√°metros:
    -----------
    data_path : str
        Ruta al dataset procesado
    test_size : float
        Proporci√≥n del conjunto de prueba
    max_depth : int
        Profundidad m√°xima del √°rbol
    criterion : str
        Criterio de divisi√≥n ('gini' o 'entropy')
    
    Retorna:
    --------
    model : DecisionTreeClassifier
        Modelo entrenado
    metrics : dict
        M√©tricas de evaluaci√≥n
    """
    print("üéØ Iniciando Clasificaci√≥n de Fallos con √Årbol de Decisi√≥n")
    print("=" * 65)
    
    # 1. CARGAR DATOS
    print(f"\nüìÅ CARGANDO DATASET: {data_path}")
    print("-" * 40)
    
    if not os.path.exists(data_path):
        print(f"‚ùå Error: No se encontr√≥ {data_path}")
        print("üí° Ejecuta main.py primero para generar el dataset procesado")
        return None, None
    
    df = pd.read_csv(data_path)
    print(f"‚úÖ Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
    
    # 2. VERIFICAR VARIABLE OBJETIVO
    if 'fallos_binarios' not in df.columns:
        print("‚ùå Error: No se encontr√≥ la columna 'fallos_binarios'")
        print("üí° Aseg√∫rate de que main.py haya creado esta columna")
        return None, None
    
    # 3. PREPARAR DATOS
    print(f"\nüîß PREPARANDO DATOS PARA CLASIFICACI√ìN")
    print("-" * 40)
    
    # Variables predictoras (todas excepto la objetivo)
    feature_cols = [col for col in df.columns if col != 'fallos_binarios']
    X = df[feature_cols]
    y = df['fallos_binarios']
    
    print(f"‚Ä¢ Features: {len(feature_cols)} variables")
    print(f"‚Ä¢ Target: fallos_binarios")
    print(f"‚Ä¢ Distribuci√≥n de clases:")
    print(f"  - Sin fallo (0): {(y == 0).sum()} ({(y == 0).sum()/len(y)*100:.1f}%)")
    print(f"  - Con fallo (1): {(y == 1).sum()} ({(y == 1).sum()/len(y)*100:.1f}%)")
    
    # 4. APLICAR MODELO USANDO LA FUNCI√ìN DEL USUARIO
    print(f"\nüå≥ ENTRENANDO MODELO DE CLASIFICACI√ìN")
    print("-" * 40)
    print(f"‚Ä¢ Conjunto de prueba: {test_size*100:.0f}%")
    print(f"‚Ä¢ Profundidad m√°xima: {max_depth}")
    print(f"‚Ä¢ Criterio: {criterion}")
    
    model, metrics = aplicar_arbol_decision(
        X=X, 
        y=y, 
        test_size=test_size, 
        random_state=42, 
        max_depth=max_depth, 
        criterion=criterion
    )
    
    # 5. MOSTRAR RESULTADOS
    mostrar_metricas_clasificacion(metrics, feature_names=feature_cols, model=model)
    
    # 6. GENERAR VISUALIZACIONES
    print(f"\nüé® GENERANDO VISUALIZACIONES")
    print("-" * 40)
    
    # Gr√°fico de importancia de caracter√≠sticas
    importances = model.feature_importances_
    feature_importance = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': importances
    }).sort_values('Importance', ascending=False)
    
    plt.figure(figsize=(12, 8))
    top_features = feature_importance.head(15)
    sns.barplot(data=top_features, x='Importance', y='Feature', hue='Feature', palette='viridis', legend=False)
    plt.title('Importancia de Caracter√≠sticas para Clasificaci√≥n de Fallos', fontsize=14, pad=20)
    plt.xlabel('Importancia')
    plt.ylabel('Caracter√≠stica')
    plt.tight_layout()
    plt.savefig('feature_importance_clasificacion.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Visualizaci√≥n de la matriz de confusi√≥n
    plt.figure(figsize=(8, 6))
    conf_matrix = metrics['confusion_matrix']
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Sin Fallo', 'Con Fallo'],
                yticklabels=['Sin Fallo', 'Con Fallo'])
    plt.title('Matriz de Confusi√≥n - Clasificaci√≥n de Fallos', fontsize=14, pad=20)
    plt.xlabel('Predicci√≥n')
    plt.ylabel('Real')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Visualizaci√≥n parcial del √°rbol
    plt.figure(figsize=(20, 12))
    plot_tree(model, 
              feature_names=feature_cols,
              class_names=['Sin Fallo', 'Con Fallo'],
              filled=True, 
              rounded=True,
              max_depth=3,  # Solo primeros niveles
              fontsize=10)
    plt.title('√Årbol de Decisi√≥n para Clasificaci√≥n de Fallos (primeros 3 niveles)', fontsize=16, pad=20)
    plt.tight_layout()
    plt.savefig('decision_tree_clasificacion.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"‚úÖ Visualizaciones guardadas:")
    print(f"   ‚Ä¢ feature_importance_clasificacion.png")
    print(f"   ‚Ä¢ confusion_matrix.png")
    print(f"   ‚Ä¢ decision_tree_clasificacion.png")
    
    print(f"\n‚úÖ CLASIFICACI√ìN COMPLETADA")
    print("=" * 65)
    
    return model, metrics

class DecisionTreeModel:
    """
    Modelo de √Årbol de Decisi√≥n para predicci√≥n de eficiencia porcentual.
    
    Esta clase implementa un modelo de √°rbol de decisi√≥n completo con preprocesamiento
    autom√°tico, entrenamiento, evaluaci√≥n y visualizaci√≥n de resultados.
    
    Attributes:
        df (pd.DataFrame): Dataset con los datos a procesar
        target_column (str): Nombre de la columna objetivo
        model (DecisionTreeRegressor): Modelo de sklearn entrenado
        results (dict): Diccionario con m√©tricas y resultados del modelo
        preprocessors (dict): Diccionario con objetos de preprocesamiento
    """
    
    def __init__(self, data_path=None, df=None, target_column='eficiencia_porcentual'):
        """
        Inicializa el modelo de √°rbol de decisi√≥n.
        
        Args:
            data_path (str, optional): Ruta al archivo de datos (Excel o CSV)
            df (pd.DataFrame, optional): DataFrame directamente cargado
            target_column (str, optional): Nombre de la columna objetivo.
                                         Por defecto 'eficiencia_porcentual'
        
        Raises:
            ValueError: Si no se proporciona ni data_path ni df
            
        Example:
            >>> # Usando DataFrame directamente
            >>> model = DecisionTreeModel(df=mi_dataframe)
            >>> 
            >>> # Usando archivo
            >>> model = DecisionTreeModel(data_path="datos.csv")
        """
        if df is not None:
            self.df = df.copy()
        elif data_path:
            self.load_data(data_path)
        else:
            raise ValueError("Debe proporcionar data_path o df")
            
        self.target_column = target_column
        self.model = None
        self.results = {}
        self.preprocessors = {}
        
    def load_data(self, data_path):
        """
        Carga los datos desde un archivo Excel o CSV.
        
        Args:
            data_path (str): Ruta al archivo de datos
            
        Raises:
            Exception: Si hay problemas al cargar el archivo
            
        Note:
            Detecta autom√°ticamente el formato del archivo basado en la extensi√≥n.
        """
        try:
            if data_path.endswith('.xlsx'):
                self.df = pd.read_excel(data_path)
            else:
                self.df = pd.read_csv(data_path)
            print(f"Datos cargados exitosamente. Forma: {self.df.shape}")
        except Exception as e:
            print(f"Error al cargar los datos: {e}")
            raise

    def preprocess_data(self):
        """
        Preprocesa los datos para el entrenamiento del modelo de √°rbol de decisi√≥n.
        
        Como el dataset procesado ya contiene solo variables num√©ricas limpias,
        el preprocesamiento es m√≠nimo:
        1. Limpieza b√°sica de la variable objetivo
        2. Identificaci√≥n de variables predictoras (todas num√©ricas)
        3. Verificaci√≥n de integridad de datos
        
        Note:
            - El dataset de entrada ya est√° preprocesado (solo variables num√©ricas)
            - No se requiere codificaci√≥n de variables categ√≥ricas
            - No se requiere imputaci√≥n (ya aplicada en main.py)
            - No se aplica normalizaci√≥n (innecesaria para √°rboles de decisi√≥n)
            
        Raises:
            ValueError: Si la variable objetivo no existe o tiene problemas
        """
        print("üîß Preprocesamiento simplificado (dataset solo con variables num√©ricas)...")
        
        # 1. LIMPIEZA B√ÅSICA DE VARIABLE OBJETIVO
        initial_shape = self.df.shape
        
        # Verificar que la variable objetivo existe
        if self.target_column not in self.df.columns:
            raise ValueError(f"Variable objetivo '{self.target_column}' no encontrada")
        
        # Limpiar valores extremos y faltantes en variable objetivo
        self.df = self.df[self.df[self.target_column].notna()]
        self.df = self.df[self.df[self.target_column] < 1e16]
        
        if self.df.shape[0] < initial_shape[0]:
            eliminados = initial_shape[0] - self.df.shape[0]
            print(f"   ‚Ä¢ Registros eliminados por problemas en variable objetivo: {eliminados}")
        
        # 2. IDENTIFICACI√ìN DE VARIABLES PREDICTORAS
        # Todas las columnas excepto la variable objetivo son num√©ricas predictoras
        self.feature_cols = [col for col in self.df.columns if col != self.target_column]
        
        print(f"   ‚Ä¢ Variables predictoras: {len(self.feature_cols)}")
        print(f"   ‚Ä¢ Variable objetivo: {self.target_column}")
        
        # 3. VERIFICACI√ìN DE INTEGRIDAD (por si acaso)
        missing_values = self.df[self.feature_cols].isnull().sum()
        if missing_values.sum() > 0:
            print(f"   ‚ö†Ô∏è  Valores faltantes encontrados (esto no deber√≠a pasar): {missing_values.sum()}")
            # Aplicar imputaci√≥n de emergencia
            self.imputer = SimpleImputer(strategy='median')
            self.df[self.feature_cols] = self.imputer.fit_transform(self.df[self.feature_cols])
            print("   ‚Ä¢ Imputaci√≥n de emergencia aplicada")
        else:
            print("   ‚úÖ Sin valores faltantes - Dataset listo para entrenamiento")
            self.imputer = None
        
        # 4. GUARDAR INFORMACI√ìN SIMPLE
        self.preprocessors = {
            'imputer': self.imputer,
            'feature_cols': self.feature_cols
        }
        
        print(f"   ‚úÖ Preprocesamiento completado: {self.df.shape[0]} registros √ó {len(self.feature_cols)} caracter√≠sticas")

    def train_model(self, test_size=0.2, random_state=42, max_depth=5):
        """
        Entrena el modelo de √°rbol de decisi√≥n y eval√∫a su rendimiento.
        
        Args:
            test_size (float, optional): Proporci√≥n del dataset para conjunto de prueba.
                                       Por defecto 0.2 (20%)
            random_state (int, optional): Semilla para reproducibilidad de resultados.
                                        Por defecto 42
            max_depth (int, optional): Profundidad m√°xima del √°rbol para evitar overfitting.
                                     Por defecto 5
        
        Returns:
            dict: Diccionario con m√©tricas de evaluaci√≥n y resultados del modelo.
                 Incluye: 'metrics', 'feature_importance', 'predictions'
        
        Note:
            - Divide autom√°ticamente los datos en entrenamiento y prueba
            - Calcula m√©tricas: MSE, RMSE, MAE, R¬≤
            - Genera tabla de importancia de caracter√≠sticas
            - Almacena resultados en self.results
            
        Example:
            >>> model = DecisionTreeModel(df=data)
            >>> model.preprocess_data()
            >>> results = model.train_model(test_size=0.3, max_depth=7)
            >>> print(f"R¬≤ Score: {results['metrics']['r2']:.4f}")
        """
        # Preparar datos
        X = self.df[self.feature_cols]
        y = self.df[self.target_column]
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        # Crear y entrenar modelo
        self.model = DecisionTreeRegressor(
            max_depth=max_depth, 
            random_state=random_state
        )
        self.model.fit(X_train, y_train)
        
        # Evaluar
        y_pred = self.model.predict(X_test)
        
        # Calcular m√©tricas
        self.results = {
            'metrics': {
                'mse': mean_squared_error(y_test, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                'mae': mean_absolute_error(y_test, y_pred),
                'r2': r2_score(y_test, y_pred)
            },
            'feature_importance': self.get_feature_importance(),
            'test_predictions': pd.DataFrame({
                'Actual': y_test,
                'Predicted': y_pred
            })
        }
        
        return self.results

    def get_feature_importance(self):
        """Obtiene la importancia de las caracter√≠sticas"""
        if self.model is None:
            raise ValueError("El modelo no ha sido entrenado a√∫n")
            
        importances = self.model.feature_importances_
        features = self.feature_cols
        feature_importance = pd.DataFrame({
            'Feature': features,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        
        return feature_importance

    def plot_tree(self, max_depth=3, figsize=(20, 10)):
        """Visualiza el √°rbol de decisi√≥n (parcial para evitar sobrecarga)"""
        if self.model is None:
            raise ValueError("El modelo no ha sido entrenado a√∫n")
            
        plt.figure(figsize=figsize)
        plot_tree(
            self.model, 
            feature_names=self.feature_cols,
            filled=True, 
            rounded=True,
            max_depth=max_depth,
            fontsize=10
        )
        plt.title("√Årbol de Decisi√≥n (primeros niveles)", pad=20)
        plt.tight_layout()
        plt.savefig('decision_tree.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_feature_importance(self, top_n=10):
        """Grafica la importancia de las caracter√≠sticas"""
        importance_df = self.get_feature_importance()
        
        plt.figure(figsize=(10, 6))
        sns.barplot(
            x='Importance', 
            y='Feature', 
            data=importance_df.head(top_n),
            hue='Feature',
            palette='viridis',
            legend=False
        )
        plt.title(f'Top {top_n} Caracter√≠sticas M√°s Importantes', pad=20)
        plt.xlabel('Importancia')
        plt.ylabel('Caracter√≠stica')
        plt.tight_layout()
        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
        plt.show()

    def print_results(self):
        """
        Imprime los resultados del modelo con formato mejorado.
        
        Muestra m√©tricas de rendimiento, importancia de caracter√≠sticas y
        an√°lisis de los resultados del modelo entrenado.
        """
        if not self.results:
            print("‚ùå No hay resultados para mostrar. Entrene el modelo primero.")
            return
        
        print("\n" + "="*60)
        print("üå≥ RESULTADOS DEL √ÅRBOL DE DECISI√ìN")
        print("="*60)
        
        # 1. INFORMACI√ìN DEL DATASET
        print(f"\nüìä INFORMACI√ìN DEL MODELO")
        print("-" * 40)
        print(f"‚Ä¢ Variables predictoras: {len(self.feature_cols)} (todas num√©ricas)")
        print(f"‚Ä¢ Variable objetivo: {self.target_column}")
        print(f"‚Ä¢ Registros procesados: {self.df.shape[0]}")
        
        # 2. M√âTRICAS DE RENDIMIENTO
        print(f"\nüìà M√âTRICAS DE RENDIMIENTO")
        print("-" * 40)
        metrics = self.results['metrics']
        
        print(f"‚Ä¢ Error Cuadr√°tico Medio (MSE):     {metrics['mse']:.4f}")
        print(f"‚Ä¢ Ra√≠z del Error Cuadr√°tico (RMSE): {metrics['rmse']:.4f}")
        print(f"‚Ä¢ Error Absoluto Medio (MAE):       {metrics['mae']:.4f}")
        print(f"‚Ä¢ Coeficiente R¬≤:                   {metrics['r2']:.4f}")
        
        # Interpretaci√≥n del R¬≤
        if metrics['r2'] >= 0.8:
            r2_interpretation = "Excelente ajuste üéØ"
        elif metrics['r2'] >= 0.6:
            r2_interpretation = "Buen ajuste üëç"
        elif metrics['r2'] >= 0.4:
            r2_interpretation = "Ajuste moderado ü§î"
        elif metrics['r2'] >= 0.0:
            r2_interpretation = "Ajuste d√©bil üòï"
        else:
            r2_interpretation = "Modelo no predictivo ‚ùå"
        
        print(f"‚Ä¢ Interpretaci√≥n R¬≤:                {r2_interpretation}")
        
        # 3. IMPORTANCIA DE CARACTER√çSTICAS
        print(f"\nüéØ IMPORTANCIA DE CARACTER√çSTICAS")
        print("-" * 40)
        importance_df = self.results['feature_importance']
        
        # Mostrar top 10 caracter√≠sticas
        top_features = importance_df.head(10)
        print("Top 10 caracter√≠sticas m√°s importantes:")
        
        for i, (_, row) in enumerate(top_features.iterrows(), 1):
            feature_name = row['Feature']
            importance = row['Importance']
            
            # Crear barra visual simple
            bar_length = int(importance * 30)  # Escalar a 30 caracteres max
            bar = "‚ñà" * bar_length + "‚ñë" * (10 - bar_length) if bar_length < 10 else "‚ñà" * 10
            
            print(f"{i:2d}. {feature_name:<22} {bar} {importance:.4f}")
        
        # 4. RECOMENDACIONES
        print(f"\nüí° RECOMENDACIONES")
        print("-" * 40)
        if metrics['r2'] < 0.3:
            print("‚Ä¢ El modelo tiene bajo poder predictivo")
            print("‚Ä¢ Considerar feature engineering o modelos m√°s complejos")
            print("‚Ä¢ Revisar si hay variables importantes faltantes")
        elif metrics['r2'] < 0.6:
            print("‚Ä¢ El modelo tiene capacidad predictiva moderada")
            print("‚Ä¢ Considerar ensemble methods (Random Forest, XGBoost)")
        else:
            print("‚Ä¢ El modelo tiene buen poder predictivo")
            print("‚Ä¢ Considerar validaci√≥n cruzada para confirmar estabilidad")
        
        # An√°lisis de caracter√≠sticas importantes
        top_feature = importance_df.iloc[0]
        if top_feature['Importance'] > 0.3:
            print(f"‚Ä¢ La variable '{top_feature['Feature']}' es dominante")
            print("‚Ä¢ Verificar si esto es esperado en el contexto del negocio")
        
        print("\n" + "="*60)

def main():
    """
    Funci√≥n principal que ejecuta modelos de √°rbol de decisi√≥n usando el dataset procesado.
    
    Ofrece dos opciones:
    1. Regresi√≥n: Predecir eficiencia_porcentual (modelo original)
    2. Clasificaci√≥n: Predecir fallos_binarios (usando funci√≥n aplicar_arbol_decision)
    
    Workflow:
        1. Carga del dataset procesado (Dataset_Talento_Procesado.csv)
        2. Selecci√≥n del tipo de modelo
        3. Entrenamiento y evaluaci√≥n
        4. Visualizaci√≥n de resultados
        
    Files Used:
        - Dataset_Talento_Procesado.csv: Dataset con preprocesamiento aplicado
        
    Files Generated:
        - Para regresi√≥n: feature_importance.png, decision_tree.png
        - Para clasificaci√≥n: feature_importance_clasificacion.png, confusion_matrix.png, decision_tree_clasificacion.png
    """
    print("üå≥ Iniciando Modelos de √Årbol de Decisi√≥n - Challenge Ingelean")
    print("=" * 70)
    
    # 1. CARGAR DATASET PROCESADO
    print("\nüìÅ CARGANDO DATASET PROCESADO")
    print("-" * 40)
    
    dataset_path = "Dataset_Talento_Procesado.csv"
    
    if not os.path.exists(dataset_path):
        print(f"‚ùå Error: No se encontr√≥ el archivo {dataset_path}")
        print("üí° Ejecuta primero main.py para generar el dataset procesado")
        return
    
    try:
        df = pd.read_csv(dataset_path)
        print(f"‚úÖ Dataset cargado exitosamente: {dataset_path}")
        print(f"üìä Forma del dataset: {df.shape}")
        print(f"üîç Columnas disponibles: {list(df.columns)}")
        
    except Exception as e:
        print(f"‚ùå Error al cargar el dataset: {str(e)}")
        return

    # 2. INFORMACI√ìN DEL DATASET
    print(f"\nüìã INFORMACI√ìN DEL DATASET PROCESADO")  
    print("-" * 40)
    print(f"‚úÖ Valores nulos eliminados mediante imputaci√≥n")
    print(f"‚úÖ Variable 'fallos_binarios' agregada")
    print(f"üìä Valores nulos restantes:")
    nulls = df.isnull().sum()
    print(nulls[nulls > 0] if nulls.sum() > 0 else "   Ninguno - Dataset completamente limpio")

    # 3. SELECCI√ìN DEL TIPO DE MODELO
    print(f"\nüéØ SELECCI√ìN DEL TIPO DE MODELO")
    print("-" * 40)
    print("Opciones disponibles:")
    print("1. Regresi√≥n: Predecir eficiencia porcentual (modelo original)")
    print("2. Clasificaci√≥n: Predecir fallos binarios (nueva funci√≥n)")
    
    # Por defecto ejecutar ambos modelos para demostraci√≥n completa
    print("\nüöÄ Ejecutando ambos modelos para an√°lisis completo...\n")
    
    # 4A. MODELO DE CLASIFICACI√ìN DE FALLOS (NUEVO)
    print("="*70)
    print("üéØ MODELO 1: CLASIFICACI√ìN DE FALLOS")
    print("="*70)
    
    model_clasificacion, metrics_clasificacion = clasificar_fallos_con_arbol(
        data_path=dataset_path,
        test_size=0.3,
        max_depth=5,
        criterion='gini'
    )
    
    # 4B. MODELO DE REGRESI√ìN ORIGINAL 
    print("\n" + "="*70)
    print("üìà MODELO 2: REGRESI√ìN DE EFICIENCIA")
    print("="*70)
    
    # Verificar que la columna objetivo existe para regresi√≥n
    target_column = 'eficiencia_porcentual'
    if target_column not in df.columns:
        print(f"‚ùå Error: No se encontr√≥ la columna objetivo '{target_column}'")
        print("üí° Continuando solo con clasificaci√≥n...")
    else:
        print(f"üéØ Variable objetivo: {target_column}")
        
        # Crear instancia del modelo
        dt_model = DecisionTreeModel(df=df, target_column=target_column)
        
        # Preprocesar datos
        print("üîß Preprocesando datos para el modelo...")
        dt_model.preprocess_data()
        
        # Entrenar modelo
        print("‚öôÔ∏è Entrenando √°rbol de decisi√≥n...")
        results = dt_model.train_model(test_size=0.2, random_state=42, max_depth=5)
        
        # Mostrar resultados
        dt_model.print_results()
        
        # Generar visualizaciones
        #print(f"\nüé® GENERANDO VISUALIZACIONES PARA REGRESI√ìN")
        #print("-" * 40)
        #dt_model.plot_feature_importance(top_n=10)
        #dt_model.plot_tree(max_depth=3)
    
    # 5. FINALIZACI√ìN
    print(f"\n‚úÖ AN√ÅLISIS COMPLETO FINALIZADO")
    print("=" * 70)
    print("üìÅ Archivos generados:")
    print("   Clasificaci√≥n de Fallos:")
    print("   ‚Ä¢ feature_importance_clasificacion.png")
    print("   ‚Ä¢ confusion_matrix.png") 
    print("   ‚Ä¢ decision_tree_clasificacion.png")
    
    if target_column in df.columns:
        print("   Regresi√≥n de Eficiencia:")
        print("   ‚Ä¢ feature_importance.png")
        print("   ‚Ä¢ decision_tree.png")
    
    print(f"\nüéØ Ambos modelos completados exitosamente!")
    
    if model_clasificacion is not None and metrics_clasificacion is not None:
        accuracy = metrics_clasificacion['accuracy']
        print(f"üìä Clasificaci√≥n - Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    if target_column in df.columns and 'results' in locals():
        r2_score = results['metrics']['r2']
        rmse = results['metrics']['rmse']
        print(f"üìà Regresi√≥n - R¬≤: {r2_score:.4f}, RMSE: {rmse:.4f}")

if __name__ == "__main__":
    main()